{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron Algorithm\n",
    "\n",
    "This Jupyter Notebook is dedicated to understanding and implementing the perceptron algorithm on soccer data. You can find the dataset [2022-2023 Soccer Player Stats Dataset](https://www.kaggle.com/datasets/vivovinco/20222023-football-player-stats?resource=download).\n",
    "\n",
    "The following packages are required to run the attached code:\n",
    "\n",
    "- [Plotly](https://plotly.com/python/)\n",
    "\n",
    "- [Plotly Express](https://plotly.com/python/plotly-express/)\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/docs/)\n",
    "\n",
    "- [Matplotlib.pylab](https://matplotlib.org/2.0.2/api/pyplot_api.html)\n",
    "\n",
    "- [Numpy](https://numpy.org/doc/)\n",
    "\n",
    "- [Seaborn](https://seaborn.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Import the necessary modules and the data.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Import the dataset. \n",
    "soccer = pd.read_csv(\"/Users/pstern/Desktop/INDE-577/Datasets/soccer_stats.csv\", encoding='ISO-8859-1', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Get the predictors (Goals, Assists, Passes into the box, and offsides penalties) as well as what we are predicting (Offense or Defense).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data such that we are only including players who have player more than 15 games worth of time.\n",
    "data = soccer[soccer['90s'] >= 15.0]\n",
    "\n",
    "# Just use the first 100 data points.\n",
    "data = data[:100]\n",
    "\n",
    "# For simplification, we will only use a few predictors.\n",
    "predictors = data[['Goals', 'Assists', 'PPA', 'PasOff']]\n",
    "\n",
    "# Now do the same for the position.\n",
    "y = data[['Pos']]\n",
    "\n",
    "# Convert each to a numpy array.\n",
    "y = y.values\n",
    "X = predictors.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The perceptron algorithm performs binary classification, so we need to make position binary.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert position into a binary variable where -1 is an attacker and 1 is a defender.\n",
    "# I considered forwards, forward/defenders, and forward/midfielders as attackers.\n",
    "y = np.where((y == 'FW') | (y == 'FWDF') | (y == 'FWMF') | (y == 'MFFW'), -1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Because the players played different amounts of time, we should also normalize the data.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of 90s played.\n",
    "ninetys = data['90s'].values\n",
    "\n",
    "# Divide each row by the number of 90s played to normalize.\n",
    "for i in range(X.shape[1]):\n",
    "    if ninetys[i] != 0:\n",
    "        X[:, i] = X[:, i] / ninetys[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Implement a perceptron class that, for each epoch, makes predictions and calculates the number of errors.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    # Initialize Perceptron object.\n",
    "    def __init__(self, eta = .5, epochs=50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        # Initialize random weights.\n",
    "        self.weight = np.random.rand(1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        # Iterate through the epochs.\n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "\n",
    "            # Iterate through each sample in the training set.\n",
    "            for xi, target in zip(X, y):\n",
    "\n",
    "                # Update weights based on the difference between predicted and actual class.\n",
    "                update = self.eta * (self.predict(xi) - target)\n",
    "                self.weight[:-1] -= update * xi\n",
    "                self.weight[-1] -= update\n",
    "\n",
    "                #Keep track of the number of errors.\n",
    "                errors += int(update != 0)\n",
    "\n",
    "            # If there are no errors in this epoch, return.\n",
    "            if errors == 0:\n",
    "                return self\n",
    "            else:\n",
    "                self.errors_.append(errors)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        # Calculate net input (sum of weighted inputs plus bias).\n",
    "        return np.dot(X, self.weight[:-1]) + self.weight[-1]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Predict class labels based on net input.\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Create an instance of the class to train the model.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x13360cd50>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate an instance of the Perceptron class.\n",
    "ptron = Perceptron(epochs = 1000)\n",
    "\n",
    "# Train the model.\n",
    "ptron.train(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Make predictions.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict make predictions based on training.\n",
    "y_hat = ptron.predict(X)\n",
    "\n",
    "# Compare our predictions with reality.\n",
    "sum = 0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i] == y[i][0]:\n",
    "        sum += 1\n",
    "\n",
    "sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
