# Perceptron Algorithm

## History

The Perceptron algorithm was proposed by Frank Rosenblatt in 1957. It was one of the earliest algorithms used for training artificial neural networks. The algorithm gained popularity due to its simplicity and ability to perform binary classification tasks.

## How it works

1. Initialize the weights and bias of the perceptron to random values or zeros.
2. For each training example, calculate the weighted sum of the input features and the corresponding weights.
3. Apply an activation function to the weighted sum to obtain the output of the perceptron.
4. Compare the predicted output with the actual output and adjust the weights and bias based on the error.
5. Repeat steps 2-4 until the perceptron converges or a maximum number of iterations is reached.

## Activation function

The most commonly used activation function for the perceptron algorithm is the step function, which outputs 1 if the weighted sum is greater than or equal to a threshold, and 0 otherwise. Other activation functions such as the sigmoid function or the ReLU function can also be used.

## Limitations

The Perceptron algorithm has some limitations:
- It can only classify linearly separable data.
- It may not converge if the data is not linearly separable.
- It does not handle multi-class classification problems directly.

## Usage

To use the Perceptron algorithm, you can follow these steps:
1. Prepare your training data, ensuring that it is labeled with the correct classes.
2. Initialize the weights and bias of the perceptron.
3. Train the perceptron using the training data.
4. Test the trained perceptron on new, unseen data.

## Example

The Perceptron algorithm is a binary classification algorithm that is used to classify input data into two categories. It is a type of artificial neural network that is based on the concept of a single artificial neuron called a perceptron.

## How it works

1. Initialize the weights and bias of the perceptron to random values or zeros.
2. For each training example, calculate the weighted sum of the input features and the corresponding weights.
3. Apply an activation function to the weighted sum to obtain the output of the perceptron.
4. Compare the predicted output with the actual output and adjust the weights and bias based on the error.
5. Repeat steps 2-4 until the perceptron converges or a maximum number of iterations is reached.

## Activation function

The most commonly used activation function for the perceptron algorithm is the step function, which outputs 1 if the weighted sum is greater than or equal to a threshold, and 0 otherwise. Other activation functions such as the sigmoid function or the ReLU function can also be used.

## Limitations

The Perceptron algorithm has some limitations:
- It can only classify linearly separable data.
- It may not converge if the data is not linearly separable.
- It does not handle multi-class classification problems directly.

## Usage

To use the Perceptron algorithm, you can follow these steps:
1. Prepare your training data, ensuring that it is labeled with the correct classes.
2. Initialize the weights and bias of the perceptron.
3. Train the perceptron using the training data.
4. Test the trained perceptron on new, unseen data.

## Example


